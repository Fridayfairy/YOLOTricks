# -*- coding: utf-8 -*-
"""“YOLOv8_Weighted_Dataloader.ipynb”的副本

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1J47-EHwaDln3HpY0xRtGOYx0rKvQknaJ

MIT License

Copyright (c) 2024 Mohammed Yasin

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
"""

# Download dataset
!pip install roboflow

from roboflow import Roboflow
rf = Roboflow(api_key="")
project = rf.workspace("trafficlightdetect").project("traffic-light-ke5b5")
version = project.version(10)
dataset = version.download("yolov8")

# Add path to data.yaml to fix location issues
!echo "path: /content" >> /content/Traffic-light-10/data.yaml

!pip install ultralytics

"""# Weighted Dataloader"""

from ultralytics import YOLO
from ultralytics.data.dataset import YOLODataset
import ultralytics.data.build as build
import numpy as np
import matplotlib.pyplot as plt
import cv2

class YOLOWeightedDataset(YOLODataset):
    def __init__(self, *args, mode="train", **kwargs):
        """
        Initialize the WeightedDataset.

        Args:
            class_weights (list or numpy array): A list or array of weights corresponding to each class.
        """

        super(YOLOWeightedDataset, self).__init__(*args, **kwargs)

        self.train_mode = "train" in self.prefix

        # You can also specify weights manually instead
        self.count_instances()
        class_weights = np.sum(self.counts) / self.counts
        self.agg_func = np.mean

        self.class_weights = np.array(class_weights)
        self.weights = self.calculate_weights()
        self.probabilities = self.calculate_probabilities()

    def count_instances(self):
        """
        Count the number of instances per class

        Returns:
            dict: A dict containing the counts for each class.
        """
        self.counts = [0 for i in range(len(self.data["names"]))]
        for label in self.labels:
            cls = label['cls'].reshape(-1).astype(int)
            for id in cls:
                self.counts[id] += 1

        self.counts = np.array(self.counts)
        self.counts = np.where(self.counts == 0, 1, self.counts)

    def calculate_weights(self):
        """
        Calculate the aggregated weight for each label based on class weights.

        Returns:
            list: A list of aggregated weights corresponding to each label.
        """
        weights = []
        for label in self.labels:
            cls = label['cls'].reshape(-1).astype(int)

            # Give a default weight to background class
            if cls.size == 0:
              weights.append(1)
              continue

            # Take mean of weights
            # You can change this weight aggregation function to aggregate weights differently
            # weight = np.mean(self.class_weights[cls])
            # weight = np.max(self.class_weights[cls])
            weight = self.agg_func(self.class_weights[cls])
            weights.append(weight)
        return weights

    def calculate_probabilities(self):
        """
        Calculate and store the sampling probabilities based on the weights.

        Returns:
            list: A list of sampling probabilities corresponding to each label.
        """
        total_weight = sum(self.weights)
        probabilities = [w / total_weight for w in self.weights]
        return probabilities

    def __getitem__(self, index):
        """
        Return transformed label information based on the sampled index.
        """
        # Don't use for validation
        if not self.train_mode:
            return self.transforms(self.get_image_and_label(index))
        else:
            index = np.random.choice(len(self.labels), p=self.probabilities)
            return self.transforms(self.get_image_and_label(index))

# Monkey patch method
build.YOLODataset = YOLOWeightedDataset

"""# Train without weighted dataloader"""

# Revert to old class
build.YOLODataset = YOLODataset

model = YOLO("yolov8n.pt")

results = model.train(data="/content/Traffic-light-10/data.yaml", epochs=50)

# Verify the type of dataset used
model.trainer.train_loader.dataset

img = cv2.imread("runs/detect/train/train_batch1.jpg")[...,::-1]

# Training plots will be unbalanced
plt.imshow(img)

"""# Train with weighted dataloader"""

# Monkey patch method to use weighted dataloader
# This might not work with multi-GPU training.
# Go to the end of the notebook for multi-GPU workaround.
build.YOLODataset = YOLOWeightedDataset

model = YOLO("yolov8n.pt")

results = model.train(data="/content/Traffic-light-10/data.yaml", epochs=50)

# Verify the type of dataset used. It should say
# YOLOWeightedDataset
model.trainer.train_loader.dataset

img = cv2.imread("runs/detect/train1/train_batch0.jpg")[...,::-1]

# Training plots will be balanced
plt.imshow(img)

"""# Check class balance"""

import matplotlib.pyplot as plt
import numpy as np
from collections import Counter

def verify_class_balance(dataset, num_samples=1000):
    """
    Verifies whether the __getitem__ method in the YOLOWeightedDataset class returns a balanced class output.

    Args:
        dataset: An instance of YOLOWeightedDataset.
        num_samples: Number of samples to draw from the dataset.

    Returns:
        class_counts: A dictionary containing the class counts.
    """
    all_labels = []
    num_samples = min(len(dataset.labels), num_samples)

    if dataset.train_mode:
        choices = np.random.choice(len(dataset.labels), size=num_samples, p=dataset.probabilities)
    else:
        choices = np.random.choice(len(dataset.labels), size=num_samples, replace=False)

    for i in choices:
        label = dataset.labels[i]["cls"]
        all_labels.extend(label.reshape(-1).astype(int))

    class_counts = Counter(all_labels)
    return class_counts

def plot_class_balance(weighted_cnts, unweighted_cnts, class_names):
    """
    Plots the comparison of class distribution between training and validation modes.

    Args:
        weighted_cnts: A dictionary containing the class counts in weighted mode.
        unweighted_cnts: A dictionary containing the class counts in unweighted mode.
        class_names: A list of class names.
    """
    classes = range(len(class_names))
    weighted_values = [weighted_cnts.get(c, 0) for c in classes]
    unweighted_values = [unweighted_cnts.get(c, 0) for c in classes]

    width = 0.35  # Bar width

    fig, ax = plt.subplots()
    ax.bar(classes, unweighted_values, width, label='Normal mode')
    ax.bar([c + width for c in classes], weighted_values, width, label='Weighted Mode')

    ax.set_xlabel('Class')
    ax.set_ylabel('Count')
    ax.set_title('Class Distribution in Normal vs Weighted Modes')
    ax.set_xticks([c + width / 2 for c in classes])
    ax.set_xticklabels(class_names, rotation=45, ha='right')
    ax.legend()

    plt.show()

# You can test different aggregation functions np.max, np.sum, np.median, np.mean
model.trainer.train_loader.dataset.agg_func = np.sum
model.trainer.train_loader.dataset.weights = model.trainer.train_loader.dataset.calculate_weights()
model.trainer.train_loader.dataset.probabilities = model.trainer.train_loader.dataset.calculate_probabilities()

# Get class counts in weighted mode
model.trainer.train_loader.dataset.train_mode = True
weighted_counts = verify_class_balance(model.trainer.train_loader.dataset, num_samples=1000)

# Get class counts in default mode
model.trainer.train_loader.dataset.train_mode = False
default_counts = verify_class_balance(model.trainer.train_loader.dataset, num_samples=1000)

# Plot the comparison
plot_class_balance(weighted_counts, default_counts, set(model.trainer.train_loader.dataset.data["names"].values()))

"""# Monkey-patching for multi-GPU"""

# Use callbacks to monkey-patch

def patch_dataset(trainer):
  from ultralytics.data.dataset import YOLODataset
  import ultralytics.data.build as build
  import numpy as np

  class YOLOWeightedDataset(YOLODataset):
      def __init__(self, *args, mode="train", **kwargs):
          """
          Initialize the WeightedDataset.

          Args:
              class_weights (list or numpy array): A list or array of weights corresponding to each class.
          """

          super(YOLOWeightedDataset, self).__init__(*args, **kwargs)

          self.train_mode = "train" in self.prefix

          # You can also specify weights manually instead
          self.count_instances()
          class_weights = np.sum(self.counts) / self.counts
          self.agg_func = np.mean

          self.class_weights = np.array(class_weights)
          self.weights = self.calculate_weights()
          self.probabilities = self.calculate_probabilities()

      def count_instances(self):
          """
          Count the number of instances per class

          Returns:
              dict: A dict containing the counts for each class.
          """
          self.counts = [0 for i in range(len(self.data["names"]))]
          for label in self.labels:
              cls = label['cls'].reshape(-1).astype(int)
              for id in cls:
                  self.counts[id] += 1

          self.counts = np.array(self.counts)
          self.counts = np.where(self.counts == 0, 1, self.counts)

      def calculate_weights(self):
          """
          Calculate the aggregated weight for each label based on class weights.

          Returns:
              list: A list of aggregated weights corresponding to each label.
          """
          weights = []
          for label in self.labels:
              cls = label['cls'].reshape(-1).astype(int)

              # Give a default weight to background class
              if cls.size == 0:
                weights.append(1)
                continue

              # Take mean of weights
              # You can change this weight aggregation function to aggregate weights differently
              # weight = np.mean(self.class_weights[cls])
              # weight = np.max(self.class_weights[cls])
              weight = self.agg_func(self.class_weights[cls])
              weights.append(weight)
          return weights

      def calculate_probabilities(self):
          """
          Calculate and store the sampling probabilities based on the weights.

          Returns:
              list: A list of sampling probabilities corresponding to each label.
          """
          total_weight = sum(self.weights)
          probabilities = [w / total_weight for w in self.weights]
          return probabilities

      def __getitem__(self, index):
          """
          Return transformed label information based on the sampled index.
          """
          # Don't use for validation
          if not self.train_mode:
              return self.transforms(self.get_image_and_label(index))
          else:
              index = np.random.choice(len(self.labels), p=self.probabilities)
              return self.transforms(self.get_image_and_label(index))

       build.YOLODataset = YOLOWeightedDataset

model = YOLO("yolov8n.pt")

model.add_callback("on_pretrain_routine_start", patch_dataset)

results = model.train(data="/content/Traffic-light-10/data.yaml", epochs=50)